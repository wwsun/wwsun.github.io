---
title: Pre-training
tags:
draft: false
description: Pre-training
url:
---
可以将 **预训练（Pre-training）** 理解为大型语言模型（LLM）的“通识教育”阶段。

在进入具体的指令微调（SFT）或强化学习（RLHF）之前，模型需要先通过预训练来掌握人类语言的底层统计规律、逻辑常识甚至是代码结构。

---

## 1. 核心定义：自监督学习

预训练本质上是一个**自监督学习（Self-supervised Learning）**的过程。

与传统的监督学习（需要人工标注 Label，如：这张图是猫，那张图是狗）不同，预训练不需要人工贴标签。它的数据就是互联网上几乎所有的公开文本（Common Crawl、维基百科、GitHub 代码、书籍等）。

- **训练目标（Objective Function）：** 预测下一个 Token（Next Token Prediction）。
    
- **数学本质：** 给定序列 $x_1, x_2, \dots, x_{t-1}$，模型需要计算条件概率 $P(x_t \mid x_1, \dots, x_{t-1})$，并使预测值与实际文本的交叉熵损失最小化。
    

## 2. 预训练到底在“练”什么？

在这个阶段，模型虽然没有被教导如何回答问题，但它在海量数据中习得了三种核心能力：

- **语法与句法（Grammar）：** 它学会了主谓宾结构，知道“吃”后面通常接“饭”而不是“云”。
    
- **世界知识（World Knowledge）：** 通过阅读大量的百科和新闻，模型记住了“拿破仑出生于科西嘉岛”或者“水分子的化学式是 $H_2O$”。
    
- **推理线索（Reasoning Patterns）：** 通过阅读数学题解和逻辑论述，模型开始模仿逻辑推导的步骤（尽管此时它还不一定能稳定输出）。
    

## 3. 技术视角：计算开销与参数

理解预训练需要对“规模”有直观的感受：

|**维度**|**预训练阶段 (Pre-training)**|**微调阶段 (Fine-tuning)**|
|---|---|---|
|**数据量**|万亿级 (Trillions of tokens)|万级/十万级 (High-quality instructions)|
|**算力消耗**|极高（数千张 H100 运行数月）|较低（单机多卡几天甚至几小时）|
|**学习重点**|学习特征提取与通用分布|学习遵循特定格式与任务指令|

## 4. 为什么说它是“Base Model”？

预训练出来的产物被称为 **基础模型（Base Model）**。

==如果你对一个仅经过预训练的模型输入：“请写一段关于人工智能的代码。”

==它可能不会给你代码，而是由于它在预训练中看过很多类似的文章，它会接着你的话往下写：“……并讨论它对人类社会的潜在影响。”

**它更像是一个概率分布的模拟器，而不是一个可以交互的助手。**

---

## 5. 总结

预训练就是利用 **Transformer 架构** 的并行计算能力，在**极大规模的无标注数据集**上，通过**最小化预测误差**，将人类文明的知识压缩进**模型参数**的过程。

> 如果把模型比作一个大脑，预训练就是在构建神经元之间最基础、最广泛的连接。
