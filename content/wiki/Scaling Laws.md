---
title: Scaling Laws
tags:
draft: false
description: Scaling Laws
source:
---
如果把 [[Pre-training]]看作是“炼丹”，那么 Scaling Laws 就是那本告诉你要放多少料、烧多久火的“炼丹准则”。

它描述了模型的性能（通常用 Cross Entropy Loss 衡量）与三个核心变量——**计算量 ($C$)**、**模型参数量 ($N$)** 和 **数据量 ($D$)** 之间的经验性数学关系。

简单来说，Scaling Laws 告诉我们：**如果你想让模型更聪明，你应该按比例增加多少算力、多少参数和多少数据。**

---

## 1. 核心公式：幂律分布 (Power Law)

OpenAI 在 2020 年的论文中指出，模型的性能并不是随机提升的，而是遵循严谨的幂律关系：

$$L(N, D) \propto \left( \frac{N}{N_0} \right)^{-\alpha} + \left( \frac{D}{D_0} \right)^{-\beta}$$

其中 $L$ 是测试集上的损失函数（Loss），$N$ 是参数量，$D$ 是训练 Token 数。这说明：

- **可预测性**：即使模型还没跑起来，我们也能通过小规模实验预导出：当参数扩大 10 倍、数据扩大 10 倍时，Loss 会降到多少。
    
- **边际效益递减**：随着规模增大，Loss 的下降速度会变慢，但**只要投入不停止，性能提升就不会停止**。
    

---

## 2. 两个流派：OpenAI vs. DeepMind (Chinchilla)

关于如何最优地分配资源，业界经历了一次重大的认知迭代，这对于理解现在的模型设计（如 Llama 3）至关重要。

### A. OpenAI 流派 (Kaplan et al., 2020)

- **观点**：参数量 ($N$) 的重要性高于数据量 ($D$)。
    
- **结论**：==如果你有 10 倍的算力，你应该把大部分钱花在把模型做大（增加 $N$），而只增加少量的训练数据。==
    
- **产物**：GPT-3（175B 参数，但只用了 300B Tokens 训练）。
    

### B. DeepMind 流派 (Chinchilla Laws, 2022)

- **观点**：参数量和数据量应该**同比例**增加。
    
- **结论**：==大多数模型其实都“训练不足”（Under-trained）。为了达到最优成本收益比，每增加 1 个参数，至少需要对应增加 20 个训练 Token。==
    
- **产物**：Chinchilla 模型（70B 参数，用了 1.4T Tokens 训练）。它的参数比 GPT-3 小得多，但效果却更好。
    

---

## 3. 为什么 Scaling Laws 对工程界意义重大？

### A. 确定性避坑

训练一个万亿级（Trillion-parameter）模型的成本高达数千万甚至上亿美元。Scaling Laws 让架构师可以在 1/1000 规模的实验上验证架构改动（比如新的 Attention 变体）是否有效。如果小模型不符合 Scaling Law 的提升曲线，那么在大模型上大概率也会失败。

### B. 涌现现象 (Emergence)

虽然 Loss 的下降是平滑的，但**具体能力的获得往往是非线性的**。

当规模跨过某个特定的阈值（Phase Transition）时，模型会突然学会某些之前完全不会的技能，比如多步数学推理、理解冷笑话或编写复杂的代码。这就像水温从 99°C 到 100°C 的质变。

---

## 4. 计算机工程视角的挑战：Scaling 的墙

作为开发者，你需要意识到 Scaling Laws 正在撞上物理和资源的边界：

1. **数据墙 (Data Wall)**：互联网上的高质量文本数据快被抽干了。现在的研究重点正转向合成数据（Synthetic Data）和多模态数据。
    
2. **算力墙 (Compute Wall)**：训练一次大模型需要消耗一个中型城市的电力，且 GPU 集群的通信带宽（NVLink）限制了并行规模。
    
3. **内存墙 (Memory Wall)**：模型参数越大，推理时的 VRAM 占用就越高，这催生了我们之前讨论的 **MoE（混合专家模型）**——在保持高参数量的同时，降低单次推理的激活计算量。
    
