---
title: 从信息简史到 AI 时代的个人学习
date: 2026-02-06 10:59:49
tags:
  - thinking
  - AIGC
draft: false
description: 从信息简史到 AI 时代的个人学习
source:
---
**LLM 本质上是基于概率的“预测机”，它们通过处理海量数据来降低文本的“熵”（不确定性）。**

个人学习与发展建议

---

### 一、 应对“信息洪流”（The Flood）：重构注意力过滤器

书末提到的“巴别图书馆”困境在今天已成现实。信息不再稀缺，**注意力**和**意义**才是稀缺资源。

**1. 从“信息囤积者”转变为“高信噪比”筛选者**

- **理论背景：** 信息只有在消除不确定性时才有价值，否则就是噪声。
    
- **实践建议：**
    
    - **利用 AI 作为“降噪”过滤器：** 既然 AI 擅长压缩信息（Compression），就利用它来处理低密度的内容。例如，用 AI 快速提取长文摘要、会议记录的核心论点，而非花费时间通读。
        
    - **建立“反推荐算法”机制：** 算法推荐倾向于推送“低熵”（符合你既有认知、易于预测）的内容。你需要主动寻找“高熵”信息——即那些挑战你认知、处于你知识盲区的严肃长内容（英文通常称为 Deep Reads）。
        
    - **行动：** 每天限制被动接收信息流（Feed）的时间，增加主动检索（Search & Query）的比例。
        

**2. 区分“数据”（Data）与“智慧”（Wisdom）**

- **理论背景：** DIKW 模型（数据-信息-知识-智慧）。LLM 处于 Information 和 Knowledge 的中间层，它拥有几乎无限的“事实”，但缺乏对真实世界的体验和伦理判断。
    
- **实践建议：**
    
    - 不要与 AI 竞争记忆力或百科全书式的知识储备。
        
    - **专注于“最后一公里”的整合：** 培养将 AI 提供的碎片化知识串联成解决现实问题方案的能力。
        

### 二、 利用“冗余”（Redundancy）：外包预测性工作

香农证明了英文文本具有约 50% 的冗余度。LLM 的核心能力正是基于上下文预测下一个 Token，这意味着它们最擅长处理具有高度“冗余性”和“模式化”的任务。

**1. 识别并外包“低熵”工作**

- **理论背景：** 凡是可以通过统计规律大概率预测的内容，都是低熵的。
    
- **实践建议：**
    
    - **代码与公文：** 样板代码（Boilerplate）、格式化邮件、基础翻译、数据清洗，这些都是高冗余任务。必须熟练使用 Cursor、GitHub Copilot 或 ChatGPT 来自动化这些流程。
        
    - **思维逆转：** 如果你的输出（无论是代码、文章还是策划案）能轻易被 LLM 完美预测，说明你的工作缺乏独创性（Surprisal）。这应成为你自我评估的警钟。
        

**2. 深耕“高熵”技能（High-Entropy Skills）**

- **理论背景：** 信息量与“惊奇度”（Surprisal）成正比。
    
- **实践建议：**
    
    - **培养 AI 难以模拟的特质：** 复杂的同理心、跨学科的隐喻能力、在极度模糊环境下做决策的勇气、以及基于真实物理世界的非语言沟通。
        
    - **提出好问题（Prompt Engineering 的本质）：** 答案往往是确定的（低熵），而一个好的问题能通过引入新的变量来开辟新的可能性（高熵）。学习如何向 AI 提问，不仅是技术，更是逻辑和哲学的训练。
        

### 三、 回归“控制论”（Cybernetics）：人机回环

维纳的控制论强调“反馈”（Feedback）。在 AI 时代，学习不再是单向的吸收，而是通过与智能体的交互进行动态调整。

**1. 将 AI 视为“对抗性”合作伙伴**

- **理论背景：** 负反馈用于修正偏差，正反馈用于增强输出。
    
- **实践建议：**
    
    - **苏格拉底式对话：** ==不要只把 LLM 当作搜索引擎。尝试让它反驳你的观点，或者扮演特定的批评者角色（如“请从行为经济学的角度批评我的这个方案”）。==
        
    - **迭代式学习：** 写出初稿 -> 让 AI 提出修改建议 -> 人工判断并融合 -> 再让 AI 润色。在这个回环中，你的核心价值在于**判断**（Judgment），而非生成（Generation）。
        

**2. 维护认知的“主权”**

- **警惕：** 语言塑造思维。如果长期过度依赖 LLM 生成文本，个人的语言表达能力可能会退化为 LLM 的统计平均值，导致思维的同质化。
    
- **实践建议：** 坚持进行“无 AI 辅助”的深度写作和思考训练。保留自己独特的、哪怕是不完美的语言风格，因为那是你作为个体的“签名”。
    

---

### 总结：在这个时代的生存策略

我们可以用一个简单的表格来对比《信息简史》视角下的旧习惯与新策略：

|**维度**|**旧时代的习惯**|**AI 时代的策略**|**理论依据**|
|---|---|---|---|
|**获取**|囤积更多信息 (More Bits)|优化过滤机制 (Better Filters)|限制信道容量，避免过载|
|**技能**|记忆事实与模版|提出问题与整合判断|LLM 解决了冗余与存储|
|**产出**|追求标准与完美|追求“惊奇”与独创性|只有不可预测的才是信息|
|**工具**|单向使用工具|建立反馈回环|控制论与人机协作|

